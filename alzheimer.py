# -*- coding: utf-8 -*-
"""Alzheimer.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/10mQeVV9kC4nxVFuKt5kGD69iDEMrEJal
"""

from google.colab import drive
drive.mount('/content/drive')

"""# **Alzheimer's Dieases**

# **Preprocessing**

# **Guided_filter**

# **Libraries**
"""

pip install deap

pip install tensorflow

pip install tensorflow keras

import os
import numpy as np
import cv2
import matplotlib.pyplot as plt

def guided_filter(I, p, r, eps):
    """
    Guided filter implementation.

    Args:
    - I: Guidance image (single channel image, e.g., grayscale)
    - p: Filtering input image (single channel image, e.g., grayscale)
    - r: Radius of the filtering window
    - eps: Epsilon value

    Returns:
    - q: Filtered image
    """
    mean_I = cv2.boxFilter(I, cv2.CV_64F, (r, r))
    mean_p = cv2.boxFilter(p, cv2.CV_64F, (r, r))
    corr_I = cv2.boxFilter(I * I, cv2.CV_64F, (r, r))
    corr_Ip = cv2.boxFilter(I * p, cv2.CV_64F, (r, r))

    var_I = corr_I - mean_I * mean_I
    cov_Ip = corr_Ip - mean_I * mean_p

    a = cov_Ip / (var_I + eps)
    b = mean_p - a * mean_I

    mean_a = cv2.boxFilter(a, cv2.CV_64F, (r, r))
    mean_b = cv2.boxFilter(b, cv2.CV_64F, (r, r))

    q = mean_a * I + mean_b
    return q

# Input and output folders
input_folder = '/content/drive/MyDrive/Colab Notebooks/Alzheimer_s Dataset/train'
output_folder = '/content/drive/MyDrive/Colab Notebooks/Alzheimer_s Dataset/Guided Filter'

# Define parameters
radius = 5
epsilon = 0.01

# Process images from input folder and subfolders and save filtered images to output folder
for root, dirs, files in os.walk(input_folder):
    for filename in files:
        if filename.endswith('.jpg'):
            # Load input image
            input_image_path = os.path.join(root, filename)
            input_image = cv2.imread(input_image_path, cv2.IMREAD_GRAYSCALE)
            input_image = np.float64(input_image) / 255.0  # Convert to floating point

            # Apply guided filter
            filtered_image = guided_filter(input_image, input_image, radius, epsilon)

            # Display input and output images
            plt.figure(figsize=(10, 5))

            # Input Image
            plt.subplot(1, 2, 1)
            plt.imshow(input_image, cmap='gray')
            plt.axis('off')
            plt.title('Input Image')

            # Output Image
            plt.subplot(1, 2, 2)
            plt.imshow(filtered_image, cmap='gray')
            plt.axis('off')
            plt.title('Filtered Image')

            plt.show()

            # Save filtered image
            relative_path = os.path.relpath(input_image_path, input_folder)
            output_image_path = os.path.join(output_folder, relative_path)
            os.makedirs(os.path.dirname(output_image_path), exist_ok=True)
            cv2.imwrite(output_image_path, filtered_image * 255.0)  # Convert back to uint8 before saving

print("All images processed, displayed, and saved.")

"""# **bilateral_filter**"""

import os
import numpy as np
import cv2
import matplotlib.pyplot as plt

def bilateral_filter(image, diameter, sigma_color, sigma_space, filter_rate):
    """
    Apply bilateral filter to the input image.

    Parameters:
        image (numpy.ndarray): Input image (grayscale or color).
        diameter (int): Diameter of each pixel neighborhood.
        sigma_color (float): Filter sigma in the color space.
        sigma_space (float): Filter sigma in the coordinate space.
        filter_rate (float): Rate at which to adjust sigma_color and sigma_space based on the input image.

    Returns:
        numpy.ndarray: Filtered image.
    """
    filtered_image = np.zeros_like(image)

    if len(image.shape) == 3:  # Color image
        for channel in range(image.shape[2]):
            filtered_image[:, :, channel] = cv2.bilateralFilter(image[:, :, channel], diameter, int(sigma_color * filter_rate), int(sigma_space * filter_rate))
    else:  # Grayscale image
        filtered_image = cv2.bilateralFilter(image, diameter, int(sigma_color * filter_rate), int(sigma_space * filter_rate))

    return filtered_image

def sharpen_image(image):
    """
    Apply image sharpening to the input image.

    Parameters:
        image (numpy.ndarray): Input image (grayscale or color).

    Returns:
        numpy.ndarray: Sharpened image.
    """
    # Define the sharpening kernel
    kernel = np.array([[-1, -1, -1],
                       [-1, 9, -1],
                       [-1, -1, -1]])

    # Apply the kernel to the image
    sharpened_image = cv2.filter2D(image, -1, kernel)

    return sharpened_image

# Define input folder containing subfolders with images
input_folder = "/content/drive/MyDrive/Colab Notebooks/Alzheimer_s Dataset/Guided Filter"

# Define output folder
output_folder = "/content/drive/MyDrive/Colab Notebooks/Alzheimer_s Dataset/bilateral filter"
os.makedirs(output_folder, exist_ok=True)

# Iterate over all subfolders and their images
for root, dirs, files in os.walk(input_folder):
    for filename in files:
        # Check if the file is an image
        if not filename.lower().endswith(('.png', '.jpg', '.jpeg', '.bmp')):
            print(f"Skipping non-image file: {filename}")
            continue

        # Construct full path to the image
        image_path = os.path.join(root, filename)

        # Attempt to read the image
        image = cv2.imread(image_path)

        # Check if the image reading was successful
        if image is None:
            print(f"Error: Unable to read image: {image_path}")
            continue

        # Convert image to grayscale
        gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)

        # Define bilateral filter parameters and filter rate
        diameter = 9
        sigma_color = 75
        sigma_space = 75
        filter_rate = 0.5  # Adjust this rate as needed

        # Apply bilateral filter
        filtered_image = bilateral_filter(gray_image, diameter, sigma_color, sigma_space, filter_rate)

        # Sharpen the filtered image
        sharpened_image = sharpen_image(filtered_image)

        # Display input and output images side by side
        plt.figure(figsize=(10, 5))

        # Input Image
        plt.subplot(1, 2, 1)
        plt.imshow(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))
        plt.axis('off')
        plt.title('Input Image')

        # Output Image
        plt.subplot(1, 2, 2)
        plt.imshow(sharpened_image, cmap='gray')
        plt.axis('off')
        plt.title('Output Image')

        plt.show()

        # Save the processed image to the output folder
        relative_path = os.path.relpath(image_path, input_folder)
        output_path = os.path.join(output_folder, relative_path)
        os.makedirs(os.path.dirname(output_path), exist_ok=True)  # Create subdirectories if necessary
        cv2.imwrite(output_path, sharpened_image)

"""# **Segmentation-Fully Convolutional Network (FCN) Algorithm**"""

import tensorflow as tf
import cv2
import os
import numpy as np
import matplotlib.pyplot as plt

def fcn_model(input_shape, num_classes):
    inputs = tf.keras.Input(shape=input_shape)

    # Encoding layers
    x = tf.keras.layers.Conv2D(64, (3, 3), activation='relu', padding='same')(inputs)
    x = tf.keras.layers.Conv2D(64, (3, 3), activation='relu', padding='same')(x)
    x = tf.keras.layers.MaxPooling2D((2, 2), strides=(2, 2))(x)

    x = tf.keras.layers.Conv2D(128, (3, 3), activation='relu', padding='same')(x)
    x = tf.keras.layers.Conv2D(128, (3, 3), activation='relu', padding='same')(x)
    x = tf.keras.layers.MaxPooling2D((2, 2), strides=(2, 2))(x)

    x = tf.keras.layers.Conv2D(256, (3, 3), activation='relu', padding='same')(x)
    x = tf.keras.layers.Conv2D(256, (3, 3), activation='relu', padding='same')(x)
    x = tf.keras.layers.MaxPooling2D((2, 2), strides=(2, 2))(x)

    # Decoding layers
    x = tf.keras.layers.Conv2D(512, (3, 3), activation='relu', padding='same')(x)
    x = tf.keras.layers.Conv2D(512, (3, 3), activation='relu', padding='same')(x)
    x = tf.keras.layers.Conv2DTranspose(256, (2, 2), strides=(2, 2), padding='same')(x)

    x = tf.keras.layers.Conv2D(256, (3, 3), activation='relu', padding='same')(x)
    x = tf.keras.layers.Conv2D(256, (3, 3), activation='relu', padding='same')(x)
    x = tf.keras.layers.Conv2DTranspose(128, (2, 2), strides=(2, 2), padding='same')(x)

    x = tf.keras.layers.Conv2D(128, (3, 3), activation='relu', padding='same')(x)
    x = tf.keras.layers.Conv2D(128, (3, 3), activation='relu', padding='same')(x)
    x = tf.keras.layers.Conv2DTranspose(64, (2, 2), strides=(2, 2), padding='same')(x)

    x = tf.keras.layers.Conv2D(64, (3, 3), activation='relu', padding='same')(x)
    x = tf.keras.layers.Conv2D(64, (3, 3), activation='relu', padding='same')(x)

    outputs = tf.keras.layers.Conv2D(num_classes, (1, 1), activation='softmax', padding='same')(x)

    model = tf.keras.Model(inputs, outputs)
    return model

# Example usage:
input_shape = (256, 256, 3)  # Example input shape (height, width, channels)
num_classes = 21  # Example number of segmentation classes

fcn = fcn_model(input_shape, num_classes)
fcn.summary()
# Path to the main folder containing subfolders with images
main_folder_path = '/content/drive/MyDrive/Colab Notebooks/Alzheimer_s Dataset/bilateral filter'

# Output folder to save segmented images
output_folder = '/content/drive/MyDrive/Colab Notebooks/Alzheimer_s Dataset/segmented image'

# Create the output folder if it doesn't exist
os.makedirs(output_folder, exist_ok=True)

# Iterate over all subfolders and process images in each subfolder
for root, dirs, files in os.walk(main_folder_path):
    for file_name in files:
        # Check if the file is an image (you can add more image extensions if needed)
        if file_name.endswith('.jpg') or file_name.endswith('.jpeg') or file_name.endswith('.png'):
            # Load the image
            image = cv2.imread(os.path.join(root, file_name))

            # Convert image to grayscale
            gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)

            # Threshold the grayscale image to get binary mask for black regions
            lower_black = 0
            upper_black = 70
            mask = cv2.inRange(gray, lower_black, upper_black)

            # Bitwise AND with original image to extract black regions
            segmented_image = cv2.bitwise_and(image, image, mask=mask)

            # Save the segmented image
            segmented_image_path = os.path.join(output_folder, os.path.splitext(file_name)[0] + '_segmented.jpg')
            cv2.imwrite(segmented_image_path, segmented_image)

            # Display input image, mask image, and segmented image
            plt.figure(figsize=(12, 6))

            # Input image
            plt.subplot(1, 3, 1)
            plt.imshow(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))
            plt.title('Input Image')
            plt.axis('off')

            # Mask image
            plt.subplot(1, 3, 2)
            plt.imshow(mask, cmap='gray')
            plt.title('Mask Image')
            plt.axis('off')

            # Segmented image
            plt.subplot(1, 3, 3)
            plt.imshow(cv2.cvtColor(segmented_image, cv2.COLOR_BGR2RGB))
            plt.title('Segmented Image')
            plt.axis('off')

            plt.show()

"""# **Feature Extraction**"""

import cv2
import os
import numpy as np
from skimage import io, measure, feature
import pandas as pd
import numpy as np
import cv2
from scipy.special import comb
from scipy.special import factorial

def calculate_LBP(image):
    # Convert the image to grayscale
    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)

    # Initialize LBP image
    lbp_image = np.zeros_like(gray)

    # Define 8-neighbors circularly
    neighbors = [(1, 0), (1, -1), (0, -1), (-1, -1),
                 (-1, 0), (-1, 1), (0, 1), (1, 1)]

    rows, cols = gray.shape

    for i in range(1, rows-1):
        for j in range(1, cols-1):
            center_pixel = gray[i, j]
            lbp_code = 0
            for idx, (dx, dy) in enumerate(neighbors):
                # Compare pixel intensity with center pixel
                if gray[i+dx, j+dy] >= center_pixel:
                    lbp_code += 2 ** idx
            lbp_image[i, j] = lbp_code

    return lbp_image

def calculate_Zernike_moments(image, n, m):
    # Convert the image to grayscale
    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)

    # Normalize the image intensities to the range [0, 1]
    normalized_image = gray.astype(np.float32) / 255.0

    # Get the dimensions of the image
    rows, cols = gray.shape

    # Initialize Zernike moments
    Z = 0

    # Define polar coordinates
    rho, theta = np.meshgrid(np.linspace(0, 1, rows), np.linspace(0, 2*np.pi, cols))

    # Calculate Zernike moments using the provided equations
    for i in range(rows):
        for j in range(cols):
            Z += normalized_image[i, j] * np.exp(1j * m * theta[i, j]) * Zernike_polynomial(rho[i, j], n, m)

    Z *= (n + 1) / np.pi

    return Z

def Zernike_polynomial(rho, n, m):
    val = 0
    for s in range((n - np.abs(m)) // 2 + 1):
        val += ((-1) ** s * factorial(n - s)) / (factorial(s) * factorial((n - np.abs(m)) // 2 - s) * factorial((n + np.abs(m)) // 2 - s)) * rho ** (n - 2 * s)
    return val
def compute_glcm(image, d):
    # Compute GLCM for a given distance d
    rows, cols = image.shape
    glcm = np.zeros((256, 256))
    for i in range(rows):
        for j in range(cols-d):
            glcm[image[i, j], image[i, j+d]] += 1
    return glcm

# Path to the main folder containing images
root_folder = '/content/drive/MyDrive/Colab Notebooks/Alzheimer_s Dataset/segmented image'

# List to store feature vectors for all images
all_features = []

# Iterate through all subfolders and files in the root folder
for folder_name, subfolders, filenames in os.walk(root_folder):
    for filename in filenames:
        if filename.endswith(('.png', '.jpg', '.jpeg')):
            print(f"Processing {filename}...")
            # Load the image
            image_path = os.path.join(folder_name, filename)

            # Ensure Grayscale Image
            image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)
            if image is None:
                print(f"Error loading {filename}")
                continue

            # Check Image Shape
            print(f"Image shape: {image.shape}")

            # Texture Feature Extraction
            glcm = compute_glcm(image, 1)
            contrast = np.sum(glcm * np.square(np.arange(256) - np.mean(glcm)))  # Contrast feature
            dissimilarity = np.sum(glcm * np.abs(np.arange(256) - np.mean(glcm)))  # Dissimilarity feature
            homogeneity = np.sum(glcm / (1 + np.square(np.arange(256) - np.mean(glcm))))  # Homogeneity feature
            energy = np.sum(np.square(glcm))  # Energy feature
            correlation = np.sum((np.arange(256) - np.mean(glcm)) * glcm) / (np.std(glcm) * np.std(np.arange(256)))  # Correlation feature
            entropy = -np.sum(glcm * np.log(glcm + 1e-10))  # Entropy feature

            # LBP Features
            lbp = feature.local_binary_pattern(image, 8, 1, method='uniform')
            lbphistogram, _ = np.histogram(lbp.ravel(), bins=np.arange(0, 10), range=(0, 10))
            lbpvariance = np.var(lbphistogram)  # LBP Variance feature

            # Shape Feature Extraction
            label_img = measure.label(image > 0, connectivity=image.ndim)  # No threshold used
            props = measure.regionprops_table(label_img, properties=('area', 'perimeter', 'solidity'))
            # Extract other shape features as needed

            # Combine Features into a Feature Vector
            texture_features = np.array([contrast, dissimilarity, homogeneity, energy, correlation, entropy, lbpvariance])
            shape_features = np.array([props['area'][0], props['perimeter'][0], props['solidity'][0]])  # Combine shape features
            feature_vector = np.concatenate((texture_features, shape_features))

            # Append the feature vector to the list
            all_features.append(feature_vector)

# Convert the list of feature vectors to a pandas DataFrame
df = pd.DataFrame(all_features, columns=['contrast', 'dissimilarity', 'homogeneity', 'energy', 'correlation', 'entropy', 'lbpvariance', 'area', 'perimeter', 'solidity'])

# Save the DataFrame to a CSV file
df.to_csv('/content/drive/MyDrive/Colab Notebooks/Alzheimer_s Dataset/extracted_features.csv', index=False)
import pandas as pd
import numpy as np

df=pd.read_csv('/content/drive/MyDrive/Colab Notebooks/Alzheimer_s Dataset/extracted_features.csv')
df

"""# **Feature Selection**"""

import pandas as pd
import random
from deap import base, creator, tools, algorithms
import numpy as np

import numpy as np

def initialize_population(N, M, LB, UB):
    """
    Initialize the population matrix X.

    Parameters:
        N (int): Population size.
        M (int): Dimensionality of the goal function.
        LB (float): Lower bound of the search space.
        UB (float): Upper bound of the search space.

    Returns:
        numpy.ndarray: Initialized population matrix X.
    """
    X = LB + np.random.rand(N, M) * (UB - LB)
    return X

def prey_identification(X, Fit):
    """
    Identify prey and simulate northern goshawks attacking prey.

    Parameters:
        X (numpy.ndarray): Population matrix.
        Fit (numpy.ndarray): Fitness values corresponding to each individual in the population.

    Returns:
        numpy.ndarray: Updated population matrix after prey identification and capture.
    """
    N, M = X.shape
    I = np.random.randint(1, 3, size=(N, M))  # Random vector of 1s and 2s
    r = np.random.rand(N, M)  # Random vector in range [0, 1]
    P = np.random.permutation(N)  # Random permutation of indices
    for i in range(N):
        p = P[i]
        prey = X[np.random.choice(np.delete(np.arange(N), p))]  # Randomly select prey
        X_i_P1 = X[p] + r[p] * (prey - I[p] * X[p])  # Simulate northern goshawk attacking prey
        X_i_P1_Fit = Fit(X_i_P1)
        if X_i_P1_Fit < Fit(X[p]):
            X[p] = X_i_P1
    return X

def prey_capture(X, Fit, R, t, T):
    """
    Simulate prey capture phase of northern goshawk optimization.

    Parameters:
        X (numpy.ndarray): Population matrix.
        Fit (numpy.ndarray): Fitness values corresponding to each individual in the population.
        R (float): Radius parameter.
        t (int): Current iteration.
        T (int): Maximum number of iterations.

    Returns:
        numpy.ndarray: Updated population matrix after prey capture.
    """
    N, M = X.shape
    r = np.random.rand(N, M)  # Random vector in range [0, 1]
    for i in range(N):
        X_i_P1 = X[i] + R * (2 * r[i] - 1) * X[i]  # Simulate prey capture phase
        X_i_P1_Fit = Fit(X_i_P1)
        if X_i_P1_Fit < Fit(X[i]):
            X[i] = X_i_P1
    return X

def prey_killed_exploitation(X, Fit, t, T, LB, UB):
    """
    Ensure that prey is killed (exploitation phase).

    Parameters:
        X (numpy.ndarray): Population matrix.
        Fit (numpy.ndarray): Fitness values corresponding to each individual in the population.
        t (int): Current iteration.
        T (int): Maximum number of iterations.
        LB (float): Lower bound of the search space.
        UB (float): Upper bound of the search space.

    Returns:
        numpy.ndarray: Updated population matrix after prey is killed.
    """
    N, M = X.shape
    d = M
    R = (UB - LB) / t
    r = np.random.rand(N, M)  # Random vector in range [0, 1]
    for i in range(N):
        X_i_P2 = X[i] + (1 - 2 * r[i]) * R * (UB - LB) / t  # Exploitation phase
        X_i_P2_Fit = Fit(X_i_P2)
        if X_i_P2_Fit < Fit(X[i]):
            X[i] = X_i_P2
    return X

# Example usage:
N = 100  # Population size
M = 5  # Dimensionality of the goal function
LB = -5.0  # Lower bound of the search space
UB = 5.0  # Upper bound of the search space
T = 100  # Maximum number of iterations

def Fit(x):
    """Example fitness function"""
    return np.sum(x ** 2)  # Example: Sum of squares

X = initialize_population(N, M, LB, UB)
for t in range(1, T+1):
    X = prey_identification(X, Fit)
    X = prey_capture(X, Fit, R=0.02 * (1 - t / T), t=t, T=T)
    X = prey_killed_exploitation(X, Fit, t, T, LB, UB)

best_solution = X[np.argmin(Fit(X))]
best_fitness = Fit(best_solution)

print("Best solution:", best_solution)
print("Best fitness:", best_fitness)
# Load the extracted features from the CSV file
df = pd.read_csv("/content/drive/MyDrive/Colab Notebooks/Alzheimer_s Dataset/extracted_features.csv")

# Define the fitness function
def evaluate(individual):
    # Shuffle the indices of the features
    shuffled_indices = list(range(len(individual)))
    random.shuffle(shuffled_indices)

    # Select the first 7 shuffled indices
    selected_indices = shuffled_indices[:7]

    # Create a mask for the selected features
    mask = [0] * len(individual)
    for idx in selected_indices:
        mask[idx] = 1

    selected_features = [column for column, sel in zip(df.columns, mask) if sel]
    fitness = sum(df[selected_features].sum())
    return fitness,

# Create the DEAP toolbox
creator.create("FitnessMax", base.Fitness, weights=(1.0,))
creator.create("Individual", list, fitness=creator.FitnessMax)
toolbox = base.Toolbox()
toolbox.register("attr_bool", random.randint, 0, 1)
toolbox.register("individual", tools.initRepeat, creator.Individual, toolbox.attr_bool, len(df.columns))
toolbox.register("population", tools.initRepeat, list, toolbox.individual)
toolbox.register("evaluate", evaluate)
toolbox.register("mate", tools.cxTwoPoint)
toolbox.register("mutate", tools.mutFlipBit, indpb=0.05)
toolbox.register("select", tools.selTournament, tournsize=3)

# Genetic algorithm parameters
population_size = 50
generations = 100
cxpb = 0.5
mutpb = 0.2

# Function to check if an individual is valid (contains exactly 7 features)
def is_valid(individual):
    return sum(individual) == 7

# Define genetic algorithm operators with the constraint
def mate_wrapper(ind1, ind2):
    if len(ind1) == 0 or len(ind2) == 0:
        return ind1, ind2
    return tools.cxTwoPoint(ind1, ind2)

toolbox.register("mate", mate_wrapper)

# Initialize population
population = toolbox.population(n=population_size)

# Run the genetic algorithm
for gen in range(generations):
    offspring = algorithms.varAnd(population, toolbox, cxpb=cxpb, mutpb=mutpb)
    fits = toolbox.map(toolbox.evaluate, offspring)
    for fit, ind in zip(fits, offspring):
        ind.fitness.values = fit
    population = toolbox.select(offspring, k=len(population))

# Select the best individual (highest fitness)
best_individual = tools.selBest(population, k=1)[0]

# Shuffle the indices of the best individual to get the selected features
shuffled_indices = list(range(len(best_individual)))
random.shuffle(shuffled_indices)
selected_indices = shuffled_indices[:7]

# Create a mask for the selected features
mask = [0] * len(best_individual)
for idx in selected_indices:
    mask[idx] = 1

selected_features = [column for column, sel in zip(df.columns, mask) if sel]

# Save the selected features to a CSV file
df[selected_features].to_csv('/content/drive/MyDrive/Colab Notebooks/Alzheimer_s Dataset/selected_features.csv', index=False)
import pandas as pd
import numpy as np

df=pd.read_csv("/content/drive/MyDrive/Colab Notebooks/Alzheimer_s Dataset/selected_features.csv")
df

"""# **Classification**"""

import os
import pandas as pd

# Generate data paths with labels
train_data_dir = '/content/drive/MyDrive/Colab Notebooks/Alzheimer_s Dataset/train'
filepaths = []
labels = []

folds = os.listdir(train_data_dir)

for fold in folds:
    foldpath = os.path.join(train_data_dir, fold)
    filelist = os.listdir(foldpath)
    for file in filelist:
        fpath = os.path.join(foldpath, file)

        filepaths.append(fpath)
        labels.append(fold)

# Concatenate data paths with labels into one dataframe
Fseries = pd.Series(filepaths, name='filepaths')
Lseries = pd.Series(labels, name='labels')

train_df = pd.concat([Fseries, Lseries], axis=1)

# Save DataFrame to CSV
output_csv_path = "/content/drive/MyDrive/Colab Notebooks/Alzheimer_s Dataset/test_data.csv"
train_df.to_csv(output_csv_path, index=False)

print("CSV file saved successfully.")
import pandas as pd

# Load the two CSV files
file1 = pd.read_csv("/content/drive/MyDrive/Colab Notebooks/Alzheimer_s Dataset/selected_features.csv")
file2 = pd.read_csv("/content/drive/MyDrive/Colab Notebooks/Alzheimer_s Dataset/test_data.csv")

# Concatenate the two files
concatenated_df = pd.concat([file1, file2], ignore_index=True)

# Save the concatenated DataFrame to a new CSV file
concatenated_df.to_csv("/content/drive/MyDrive/Colab Notebooks/Alzheimer_s Dataset/concatenated_file.csv", index=False)

print("Concatenation completed. Output saved to concatenated_file.csv")
import pandas as pd
import numpy as np

from sklearn.model_selection import train_test_split, cross_val_score, RandomizedSearchCV, GridSearchCV
from sklearn.metrics import confusion_matrix, classification_report, precision_score, recall_score, f1_score, RocCurveDisplay
df=pd.read_csv("/content/drive/MyDrive/Colab Notebooks/Alzheimer_s Dataset/concatenated_file.csv")
df

df['labels'].value_counts()

X = df.drop('labels', axis=1)
y = df["labels"]

X

y

# Create training & test sets: Training 70%, Test: 30%
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)
print(X_train.shape)

pd.DataFrame(y_train)

print("No. of rows in train dataset:", len(X_train))
print("No. of rows in test dataset:", len(X_test))

"""# **Proposed Algorithm**"""

import numpy as np
from sklearn.metrics import multilabel_confusion_matrix, confusion_matrix
import tensorflow as tf
from tensorflow.keras import layers, models
import tensorflow as tf
# calculates precision for 1:100 dataset with 90 tp and 30 fp
import numpy as np
from sklearn.metrics import confusion_matrix, precision_score, recall_score, f1_score
import tensorflow as tf

from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Flatten, Dense
from tensorflow.keras.optimizers import Adam
from sklearn.model_selection import train_test_split
import matplotlib.pyplot as plt
# Define Swish activation function
def swish(x):
    return x * tf.sigmoid(x)

# Define LeakyReLU activation function
def leaky_relu(x, alpha=0.1):
    return tf.maximum(alpha*x, x)

# Define LeNet-5 architecture
def LeNet5():
    model = tf.keras.models.Sequential([
        tf.keras.layers.Conv2D(6, kernel_size=(5, 5), activation='swish', input_shape=(32, 32, 1)),
        tf.keras.layers.MaxPooling2D(pool_size=(2, 2)),
        tf.keras.layers.Conv2D(16, kernel_size=(5, 5), activation='swish'),
        tf.keras.layers.MaxPooling2D(pool_size=(2, 2)),
        tf.keras.layers.Flatten(),
        tf.keras.layers.Dense(120, activation='swish'),
        tf.keras.layers.Dense(84, activation='swish'),
        tf.keras.layers.Dense(10, activation='softmax')
    ])
    return model

# Define Darknet-53 architecture
def Darknet53():
    inputs = tf.keras.layers.Input(shape=(None, None, 3))
    x = darknet_conv_block(inputs, 32, 3)
    x = darknet_res_block(x, 64, 1)
    x = darknet_res_block(x, 128, 2)
    x = darknet_res_block(x, 256, 8)
    x = darknet_res_block(x, 512, 8)
    x = darknet_res_block(x, 1024, 4)
    model = tf.keras.models.Model(inputs, x)
    return model

# Helper function to create convolutional block in Darknet-53
def darknet_conv_block(inputs, filters, kernel_size):
    x = tf.keras.layers.Conv2D(filters=filters, kernel_size=kernel_size, strides=(1, 1), padding='same')(inputs)
    x = tf.keras.layers.BatchNormalization()(x)
    x = leaky_relu(x)
    return x

# Helper function to create residual block in Darknet-53
def darknet_res_block(inputs, filters, blocks):
    x = darknet_conv_block(inputs, filters, 3)
    x = tf.keras.layers.Conv2D(filters=filters // 2, kernel_size=1, strides=(1, 1), padding='same')(x)
    x = tf.keras.layers.BatchNormalization()(x)
    x = leaky_relu(x)
    x = darknet_conv_block(x, filters, 3)

    # Adjust the shape of inputs if needed
    if inputs.shape[-1] != filters:
        inputs = tf.keras.layers.Conv2D(filters=filters, kernel_size=1, strides=(1, 1), padding='same')(inputs)

    x = tf.keras.layers.add([inputs, x])
    return x

# Instantiate LeNet-5 model
lenet_model = LeNet5()

# Instantiate Darknet-53 model
darknet_model = Darknet53()

# Compile the models
lenet_model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])
# darknet_model.compile(optimizer='adam', loss='focal_loss', metrics=['accuracy'])

# Print model summaries
print("LeNet-5 Summary:")
print(lenet_model.summary())

print("\nDarknet-53 Summary:")
print(darknet_model.summary())
# calculates precision for 1:100 dataset with 90 tp and 30 fp

# Precision calculation for binary classification
def calculate_precision(tp, fp):
    return tp / (tp + fp)

# Confusion matrix function
def plot_confusion_matrix(y_true, y_pred):
    cm = confusion_matrix(y_true, y_pred)
    plt.imshow(cm, interpolation='nearest', cmap=plt.cm.Blues)
    plt.title('Confusion Matrix')
    plt.colorbar()
    plt.xlabel('Predicted')
    plt.ylabel('Actual')
    plt.show()

# Define a function to calculate various metrics
def calculate_metrics(TP, TN, FP, FN):
    epsilon = 1e-10  # Small value to avoid division by zero
    sensitivity = TP / np.maximum(TP + FN, epsilon)
    specificity = TN / np.maximum(TN + FP, epsilon)
    precision = TP / np.maximum(TP + FP, epsilon)
    recall = TP / np.maximum(TP + FN, epsilon)
    f_measure = 2 * ((precision * recall) / np.maximum(precision + recall, epsilon))
    accuracy = (TP + TN) / np.maximum(TP + TN + FP + FN, epsilon)
    mcc_numerator = (TP * TN) - (FP * FN)
    mcc_denominator = np.sqrt((TP + FP) * (TP + FN) * (TN + FP) * (TN + FN))
    mcc = mcc_numerator / np.maximum(mcc_denominator, epsilon)
    fpr = FP / np.maximum(FP + TN, epsilon)
    fnr = FN / np.maximum(FN + TP, epsilon)
    npv = TN / np.maximum(TN + FN, epsilon)

    return {
        'sensitivity': sensitivity, 'specificity': specificity, 'precision': precision,
        'recall': recall, 'f_measure': f_measure, 'accuracy': accuracy, 'mcc': mcc,
        'fpr': fpr, 'fnr': fnr, 'npv': npv
    }


# Split the dataset into training and validation sets
x_train, x_val, y_train, y_val = train_test_split(x_train, y_train,
                                                  test_size=0.3, random_state=42)

# Train the model
history = model.fit(x_train, y_train, epochs=10, validation_data=(x_val, y_val))

# Plot training and validation accuracy
plt.figure(figsize=(12, 5))
plt.subplot(1, 2, 1)
plt.plot(history.history['accuracy'], label='Training Accuracy', marker='o')
plt.plot(history.history['val_accuracy'], label='Validation Accuracy', marker='o')
plt.title('Training and Validation Accuracy')
plt.xlabel('Epoch')
plt.ylabel('Accuracy')
plt.legend()

# Plot training and validation loss
plt.subplot(1, 2, 2)
plt.plot(history.history['loss'], label='Training Loss', marker='o')
plt.plot(history.history['val_loss'], label='Validation Loss', marker='o')
plt.title('Training and Validation Loss')
plt.xlabel('Epoch')
plt.ylabel('Loss')
plt.legend()
plt.tight_layout()
plt.show()

# Make predictions
y_pred = np.argmax(model.predict(x_test), axis=-1)

# Calculate confusion matrix
cm = confusion_matrix(y_test, y_pred)

# Extract TP, TN, FP, FN from confusion matrix
TP = np.diag(cm)
FP = np.sum(cm, axis=0) - TP
FN = np.sum(cm, axis=1) - TP
TN = np.sum(cm) - (TP + FP + FN)

# Calculate metrics
metrics = calculate_metrics(TP, TN, FP, FN)

# Print metrics
for metric_name, metric_value in metrics.items():
    print(f'{metric_name}: {metric_value}')

"""# **vgg-19 Algorithm**"""

import numpy as np
import tensorflow as tf
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense
import numpy as np
from sklearn.metrics import confusion_matrix, precision_score, recall_score, f1_score
import tensorflow as tf
from tensorflow.keras.optimizers import Adam
from sklearn.model_selection import train_test_split
import matplotlib.pyplot as plt

def VGG_19(input_shape=(224, 224, 3), num_classes=1000):
    model = Sequential()

    # Block 1
    model.add(Conv2D(64, (3, 3), activation='relu', padding='same', input_shape=input_shape))
    model.add(Conv2D(64, (3, 3), activation='relu', padding='same'))
    model.add(MaxPooling2D((2, 2), strides=(2, 2)))

    # Block 2
    model.add(Conv2D(128, (3, 3), activation='relu', padding='same'))
    model.add(Conv2D(128, (3, 3), activation='relu', padding='same'))
    model.add(MaxPooling2D((2, 2), strides=(2, 2)))

    # Block 3
    model.add(Conv2D(256, (3, 3), activation='relu', padding='same'))
    model.add(Conv2D(256, (3, 3), activation='relu', padding='same'))
    model.add(Conv2D(256, (3, 3), activation='relu', padding='same'))
    model.add(Conv2D(256, (3, 3), activation='relu', padding='same'))
    model.add(MaxPooling2D((2, 2), strides=(2, 2)))

    # Block 4
    model.add(Conv2D(512, (3, 3), activation='relu', padding='same'))
    model.add(Conv2D(512, (3, 3), activation='relu', padding='same'))
    model.add(Conv2D(512, (3, 3), activation='relu', padding='same'))
    model.add(Conv2D(512, (3, 3), activation='relu', padding='same'))
    model.add(MaxPooling2D((2, 2), strides=(2, 2)))

    # Block 5
    model.add(Conv2D(512, (3, 3), activation='relu', padding='same'))
    model.add(Conv2D(512, (3, 3), activation='relu', padding='same'))
    model.add(Conv2D(512, (3, 3), activation='relu', padding='same'))
    model.add(Conv2D(512, (3, 3), activation='relu', padding='same'))
    model.add(MaxPooling2D((2, 2), strides=(2, 2)))

    # Classification block
    model.add(Flatten())
    model.add(Dense(4096, activation='relu'))
    model.add(Dense(4096, activation='relu'))
    model.add(Dense(num_classes, activation='softmax'))

    return model

# Example usage:
input_shape = (224, 224, 3)  # Input shape of your images
num_classes = 1000  # Number of classes in your dataset

vgg19_model = VGG_19(input_shape=input_shape, num_classes=num_classes)
vgg19_model.summary()
# Precision calculation for binary classification
def calculate_precision(tp, fp):
    return tp / (tp + fp)

# Confusion matrix function
def plot_confusion_matrix(y_true, y_pred):
    cm = confusion_matrix(y_true, y_pred)
    plt.imshow(cm, interpolation='nearest', cmap=plt.cm.Blues)
    plt.title('Confusion Matrix')
    plt.colorbar()
    plt.xlabel('Predicted')
    plt.ylabel('Actual')
    plt.show()

# Define a function to calculate various metrics
def calculate_metrics(TP, TN, FP, FN):
    epsilon = 1e-10  # Small value to avoid division by zero
    sensitivity = TP / np.maximum(TP + FN, epsilon)
    specificity = TN / np.maximum(TN + FP, epsilon)
    precision = TP / np.maximum(TP + FP, epsilon)
    recall = TP / np.maximum(TP + FN, epsilon)
    f_measure = 2 * ((precision * recall) / np.maximum(precision + recall, epsilon))
    accuracy = (TP + TN) / np.maximum(TP + TN + FP + FN, epsilon)
    mcc_numerator = (TP * TN) - (FP * FN)
    mcc_denominator = np.sqrt((TP + FP) * (TP + FN) * (TN + FP) * (TN + FN))
    mcc = mcc_numerator / np.maximum(mcc_denominator, epsilon)
    fpr = FP / np.maximum(FP + TN, epsilon)
    fnr = FN / np.maximum(FN + TP, epsilon)
    npv = TN / np.maximum(TN + FN, epsilon)

    return {
        'sensitivity': sensitivity, 'specificity': specificity, 'precision': precision,
        'recall': recall, 'f_measure': f_measure, 'accuracy': accuracy, 'mcc': mcc,
        'fpr': fpr, 'fnr': fnr, 'npv': npv
    }

# Split the dataset into training and validation sets
x_train, x_val, y_train, y_val = train_test_split(x_train, y_train,
                                                  test_size=0.3, random_state=30)

# Train the model
history = model.fit(x_train, y_train, epochs=5, validation_data=(x_val, y_val))

# Plot training and validation accuracy
plt.figure(figsize=(12, 5))
plt.subplot(1, 2, 1)
plt.plot(history.history['accuracy'], label='Training Accuracy', marker='o')
plt.plot(history.history['val_accuracy'], label='Validation Accuracy', marker='o')
plt.title('Training and Validation Accuracy')
plt.xlabel('Epoch')
plt.ylabel('Accuracy')
plt.legend()

# Plot training and validation loss
plt.subplot(1, 2, 2)
plt.plot(history.history['loss'], label='Training Loss', marker='o')
plt.plot(history.history['val_loss'], label='Validation Loss', marker='o')
plt.title('Training and Validation Loss')
plt.xlabel('Epoch')
plt.ylabel('Loss')
plt.legend()
plt.tight_layout()
plt.show()

# Make predictions
y_pred = np.argmax(model.predict(x_test), axis=-1)

# Calculate confusion matrix
cm = confusion_matrix(y_test, y_pred)

# Extract TP, TN, FP, FN from confusion matrix
TP = np.diag(cm)
FP = np.sum(cm, axis=0) - TP
FN = np.sum(cm, axis=1) - TP
TN = np.sum(cm) - (TP + FP + FN)

# Calculate metrics
metrics = calculate_metrics(TP, TN, FP, FN)

# Print metrics
for metric_name, metric_value in metrics.items():
    print(f'{metric_name}: {metric_value}')

"""# **CNN Algorithm**"""

import tensorflow as tf
from tensorflow.keras import layers, models, datasets
import numpy as np
from sklearn.metrics import confusion_matrix, precision_score, recall_score, f1_score
import tensorflow as tf
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Flatten, Dense
from tensorflow.keras.optimizers import Adam
from sklearn.model_selection import train_test_split
import matplotlib.pyplot as plt
# Define the model architecture
model = models.Sequential([
    layers.Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)),
    layers.MaxPooling2D((2, 2)),
    layers.Conv2D(64, (3, 3), activation='relu'),
    layers.MaxPooling2D((2, 2)),
    layers.Conv2D(64, (3, 3), activation='relu'),
    layers.Flatten(),
    layers.Dense(64, activation='relu'),
    layers.Dense(10, activation='softmax')
])

# Compile the model
model.compile(optimizer='adam',
              loss='sparse_categorical_crossentropy',
              metrics=['accuracy'])

# Train the model
history = model.fit(train_images, train_labels, epochs=5, validation_data=(test_images, test_labels))

# Evaluate the model
test_loss, test_acc = model.evaluate(test_images, test_labels, verbose=2)
# Precision calculation for binary classification
def calculate_precision(tp, fp):
    return tp / (tp + fp)

# Confusion matrix function
def plot_confusion_matrix(y_true, y_pred):
    cm = confusion_matrix(y_true, y_pred)
    plt.imshow(cm, interpolation='nearest', cmap=plt.cm.Blues)
    plt.title('Confusion Matrix')
    plt.colorbar()
    plt.xlabel('Predicted')
    plt.ylabel('Actual')
    plt.show()

# Define a function to calculate various metrics
def calculate_metrics(TP, TN, FP, FN):
    epsilon = 1e-10  # Small value to avoid division by zero
    sensitivity = TP / np.maximum(TP + FN, epsilon)
    specificity = TN / np.maximum(TN + FP, epsilon)
    precision = TP / np.maximum(TP + FP, epsilon)
    recall = TP / np.maximum(TP + FN, epsilon)
    f_measure = 2 * ((precision * recall) / np.maximum(precision + recall, epsilon))
    accuracy = (TP + TN) / np.maximum(TP + TN + FP + FN, epsilon)
    mcc_numerator = (TP * TN) - (FP * FN)
    mcc_denominator = np.sqrt((TP + FP) * (TP + FN) * (TN + FP) * (TN + FN))
    mcc = mcc_numerator / np.maximum(mcc_denominator, epsilon)
    fpr = FP / np.maximum(FP + TN, epsilon)
    fnr = FN / np.maximum(FN + TP, epsilon)
    npv = TN / np.maximum(TN + FN, epsilon)

    return {
        'sensitivity': sensitivity, 'specificity': specificity, 'precision': precision,
        'recall': recall, 'f_measure': f_measure, 'accuracy': accuracy, 'mcc': mcc,
        'fpr': fpr, 'fnr': fnr, 'npv': npv
    }

# Split the dataset into training and validation sets
x_train, x_val, y_train, y_val = train_test_split(x_train, y_train,
                                                  test_size=0.5, random_state=30)

# Train the model
history = model.fit(x_train, y_train, epochs=5, validation_data=(x_val, y_val))

# Plot training and validation accuracy
plt.figure(figsize=(12, 5))
plt.subplot(1, 2, 1)
plt.plot(history.history['accuracy'], label='Training Accuracy', marker='o')
plt.plot(history.history['val_accuracy'], label='Validation Accuracy', marker='o')
plt.title('Training and Validation Accuracy')
plt.xlabel('Epoch')
plt.ylabel('Accuracy')
plt.legend()

# Plot training and validation loss
plt.subplot(1, 2, 2)
plt.plot(history.history['loss'], label='Training Loss', marker='o')
plt.plot(history.history['val_loss'], label='Validation Loss', marker='o')
plt.title('Training and Validation Loss')
plt.xlabel('Epoch')
plt.ylabel('Loss')
plt.legend()
plt.tight_layout()
plt.show()

# Make predictions
y_pred = np.argmax(model.predict(x_test), axis=-1)

# Calculate confusion matrix
cm = confusion_matrix(y_test, y_pred)

# Extract TP, TN, FP, FN from confusion matrix
TP = np.diag(cm)
FP = np.sum(cm, axis=0) - TP
FN = np.sum(cm, axis=1) - TP
TN = np.sum(cm) - (TP + FP + FN)

# Calculate metrics
metrics = calculate_metrics(TP, TN, FP, FN)

# Print metrics
for metric_name, metric_value in metrics.items():
    print(f'{metric_name}: {metric_value}')

"""# **DCNN Algorithm**"""

import tensorflow as tf
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout
import numpy as np
from sklearn.metrics import confusion_matrix, precision_score, recall_score, f1_score
import tensorflow as tf
from sklearn.model_selection import train_test_split
import matplotlib.pyplot as plt

def build_dcnn(input_shape, num_classes):
    model = Sequential([
        Conv2D(32, (3, 3), activation='relu', input_shape=input_shape),
        MaxPooling2D((2, 2)),
        Conv2D(64, (3, 3), activation='relu'),
        MaxPooling2D((2, 2)),
        Conv2D(128, (3, 3), activation='relu'),
        MaxPooling2D((2, 2)),
        Conv2D(128, (3, 3), activation='relu'),
        MaxPooling2D((2, 2)),
        Flatten(),
        Dropout(0.5),
        Dense(512, activation='relu'),
        Dense(num_classes, activation='softmax')
    ])
    return model

# Example usage:
input_shape = (150, 150, 3)  # Input shape of your images
num_classes = 10  # Number of classes in your dataset

dcnn_model = build_dcnn(input_shape, num_classes)
dcnn_model.summary()
# Precision calculation for binary classification
def calculate_precision(tp, fp):
    return tp / (tp + fp)

# Confusion matrix function
def plot_confusion_matrix(y_true, y_pred):
    cm = confusion_matrix(y_true, y_pred)
    plt.imshow(cm, interpolation='nearest', cmap=plt.cm.Blues)
    plt.title('Confusion Matrix')
    plt.colorbar()
    plt.xlabel('Predicted')
    plt.ylabel('Actual')
    plt.show()

# Define a function to calculate various metrics
def calculate_metrics(TP, TN, FP, FN):
    epsilon = 1e-10  # Small value to avoid division by zero
    sensitivity = TP / np.maximum(TP + FN, epsilon)
    specificity = TN / np.maximum(TN + FP, epsilon)
    precision = TP / np.maximum(TP + FP, epsilon)
    recall = TP / np.maximum(TP + FN, epsilon)
    f_measure = 2 * ((precision * recall) / np.maximum(precision + recall, epsilon))
    accuracy = (TP + TN) / np.maximum(TP + TN + FP + FN, epsilon)
    mcc_numerator = (TP * TN) - (FP * FN)
    mcc_denominator = np.sqrt((TP + FP) * (TP + FN) * (TN + FP) * (TN + FN))
    mcc = mcc_numerator / np.maximum(mcc_denominator, epsilon)
    fpr = FP / np.maximum(FP + TN, epsilon)
    fnr = FN / np.maximum(FN + TP, epsilon)
    npv = TN / np.maximum(TN + FN, epsilon)

    return {
        'sensitivity': sensitivity, 'specificity': specificity, 'precision': precision,
        'recall': recall, 'f_measure': f_measure, 'accuracy': accuracy, 'mcc': mcc,
        'fpr': fpr, 'fnr': fnr, 'npv': npv
    }



# Compile the model
model.compile(optimizer=Adam(learning_rate=0.015),
              loss='sparse_categorical_crossentropy',
              metrics=['accuracy'])

# Split the dataset into training and validation sets
x_train, x_val, y_train, y_val = train_test_split(x_train, y_train,
                                                  test_size=0.5, random_state=30)

# Train the model
history = model.fit(x_train, y_train, epochs=5, validation_data=(x_val, y_val))

# Plot training and validation accuracy
plt.figure(figsize=(12, 5))
plt.subplot(1, 2, 1)
plt.plot(history.history['accuracy'], label='Training Accuracy', marker='o')
plt.plot(history.history['val_accuracy'], label='Validation Accuracy', marker='o')
plt.title('Training and Validation Accuracy')
plt.xlabel('Epoch')
plt.ylabel('Accuracy')
plt.legend()

# Plot training and validation loss
plt.subplot(1, 2, 2)
plt.plot(history.history['loss'], label='Training Loss', marker='o')
plt.plot(history.history['val_loss'], label='Validation Loss', marker='o')
plt.title('Training and Validation Loss')
plt.xlabel('Epoch')
plt.ylabel('Loss')
plt.legend()
plt.tight_layout()
plt.show()

# Make predictions
y_pred = np.argmax(model.predict(x_test), axis=-1)

# Calculate confusion matrix
cm = confusion_matrix(y_test, y_pred)

# Extract TP, TN, FP, FN from confusion matrix
TP = np.diag(cm)
FP = np.sum(cm, axis=0) - TP
FN = np.sum(cm, axis=1) - TP
TN = np.sum(cm) - (TP + FP + FN)

# Calculate metrics
metrics = calculate_metrics(TP, TN, FP, FN)

# Print metrics
for metric_name, metric_value in metrics.items():
    print(f'{metric_name}: {metric_value}')

"""# **MLP Algorithm**"""

import tensorflow as tf
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, Dropout
import numpy as np
from sklearn.metrics import confusion_matrix, precision_score, recall_score, f1_score
import tensorflow as tf
from tensorflow.keras.datasets import mnist
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Flatten, Dense
from tensorflow.keras.optimizers import Adam
from sklearn.model_selection import train_test_split
import matplotlib.pyplot as plt

def build_mlp(input_shape, num_classes):
    model = Sequential([
        Dense(128, activation='relu', input_shape=input_shape),
        Dropout(0.5),
        Dense(64, activation='relu'),
        Dropout(0.5),
        Dense(num_classes, activation='softmax')
    ])
    return model

# Example usage:
input_shape = (784,)  # Input shape of your data
num_classes = 10  # Number of classes in your dataset

mlp_model = build_mlp(input_shape, num_classes)
mlp_model.summary()
# Precision calculation for binary classification
def calculate_precision(tp, fp):
    return tp / (tp + fp)

# Confusion matrix function
def plot_confusion_matrix(y_true, y_pred):
    cm = confusion_matrix(y_true, y_pred)
    plt.imshow(cm, interpolation='nearest', cmap=plt.cm.Blues)
    plt.title('Confusion Matrix')
    plt.colorbar()
    plt.xlabel('Predicted')
    plt.ylabel('Actual')
    plt.show()

# Define a function to calculate various metrics
def calculate_metrics(TP, TN, FP, FN):
    epsilon = 1e-10  # Small value to avoid division by zero
    sensitivity = TP / np.maximum(TP + FN, epsilon)
    specificity = TN / np.maximum(TN + FP, epsilon)
    precision = TP / np.maximum(TP + FP, epsilon)
    recall = TP / np.maximum(TP + FN, epsilon)
    f_measure = 2 * ((precision * recall) / np.maximum(precision + recall, epsilon))
    accuracy = (TP + TN) / np.maximum(TP + TN + FP + FN, epsilon)
    mcc_numerator = (TP * TN) - (FP * FN)
    mcc_denominator = np.sqrt((TP + FP) * (TP + FN) * (TN + FP) * (TN + FN))
    mcc = mcc_numerator / np.maximum(mcc_denominator, epsilon)
    fpr = FP / np.maximum(FP + TN, epsilon)
    fnr = FN / np.maximum(FN + TP, epsilon)
    npv = TN / np.maximum(TN + FN, epsilon)

    return {
        'sensitivity': sensitivity, 'specificity': specificity, 'precision': precision,
        'recall': recall, 'f_measure': f_measure, 'accuracy': accuracy, 'mcc': mcc,
        'fpr': fpr, 'fnr': fnr, 'npv': npv
    }

# Split the dataset into training and validation sets
x_train, x_val, y_train, y_val = train_test_split(x_train, y_train,
                                                  test_size=0.5, random_state=30)

# Train the model
history = model.fit(x_train, y_train, epochs=5, validation_data=(x_val, y_val))

# Plot training and validation accuracy
plt.figure(figsize=(12, 5))
plt.subplot(1, 2, 1)
plt.plot(history.history['accuracy'], label='Training Accuracy', marker='o')
plt.plot(history.history['val_accuracy'], label='Validation Accuracy', marker='o')
plt.title('Training and Validation Accuracy')
plt.xlabel('Epoch')
plt.ylabel('Accuracy')
plt.legend()

# Plot training and validation loss
plt.subplot(1, 2, 2)
plt.plot(history.history['loss'], label='Training Loss', marker='o')
plt.plot(history.history['val_loss'], label='Validation Loss', marker='o')
plt.title('Training and Validation Loss')
plt.xlabel('Epoch')
plt.ylabel('Loss')
plt.legend()
plt.tight_layout()
plt.show()

# Make predictions
y_pred = np.argmax(model.predict(x_test), axis=-1)

# Calculate confusion matrix
cm = confusion_matrix(y_test, y_pred)

# Extract TP, TN, FP, FN from confusion matrix
TP = np.diag(cm)
FP = np.sum(cm, axis=0) - TP
FN = np.sum(cm, axis=1) - TP
TN = np.sum(cm) - (TP + FP + FN)

# Calculate metrics
metrics = calculate_metrics(TP, TN, FP, FN)

# Print metrics
for metric_name, metric_value in metrics.items():
    print(f'{metric_name}: {metric_value}')

"""# **Split Data 80/20**"""

# Create training & test sets: Training 80%, Test: 20%
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)
print(X_train.shape)

"""# **Proposed**"""

import numpy as np
from sklearn.metrics import multilabel_confusion_matrix, confusion_matrix
import tensorflow as tf
from tensorflow.keras import layers, models
import tensorflow as tf

# Define Swish activation function
def swish(x):
    return x * tf.sigmoid(x)

# Define LeakyReLU activation function
def leaky_relu(x, alpha=0.1):
    return tf.maximum(alpha*x, x)

# Define LeNet-5 architecture
def LeNet5():
    model = tf.keras.models.Sequential([
        tf.keras.layers.Conv2D(6, kernel_size=(5, 5), activation='swish', input_shape=(32, 32, 1)),
        tf.keras.layers.MaxPooling2D(pool_size=(2, 2)),
        tf.keras.layers.Conv2D(16, kernel_size=(5, 5), activation='swish'),
        tf.keras.layers.MaxPooling2D(pool_size=(2, 2)),
        tf.keras.layers.Flatten(),
        tf.keras.layers.Dense(120, activation='swish'),
        tf.keras.layers.Dense(84, activation='swish'),
        tf.keras.layers.Dense(10, activation='softmax')
    ])
    return model

# Define Darknet-53 architecture
def Darknet53():
    inputs = tf.keras.layers.Input(shape=(None, None, 3))
    x = darknet_conv_block(inputs, 32, 3)
    x = darknet_res_block(x, 64, 1)
    x = darknet_res_block(x, 128, 2)
    x = darknet_res_block(x, 256, 8)
    x = darknet_res_block(x, 512, 8)
    x = darknet_res_block(x, 1024, 4)
    model = tf.keras.models.Model(inputs, x)
    return model

# Helper function to create convolutional block in Darknet-53
def darknet_conv_block(inputs, filters, kernel_size):
    x = tf.keras.layers.Conv2D(filters=filters, kernel_size=kernel_size, strides=(1, 1), padding='same')(inputs)
    x = tf.keras.layers.BatchNormalization()(x)
    x = leaky_relu(x)
    return x

# Helper function to create residual block in Darknet-53
def darknet_res_block(inputs, filters, blocks):
    x = darknet_conv_block(inputs, filters, 3)
    x = tf.keras.layers.Conv2D(filters=filters // 2, kernel_size=1, strides=(1, 1), padding='same')(x)
    x = tf.keras.layers.BatchNormalization()(x)
    x = leaky_relu(x)
    x = darknet_conv_block(x, filters, 3)

    # Adjust the shape of inputs if needed
    if inputs.shape[-1] != filters:
        inputs = tf.keras.layers.Conv2D(filters=filters, kernel_size=1, strides=(1, 1), padding='same')(inputs)

    x = tf.keras.layers.add([inputs, x])
    return x

# Instantiate LeNet-5 model
lenet_model = LeNet5()

# Instantiate Darknet-53 model
darknet_model = Darknet53()

# Compile the models
lenet_model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])
# darknet_model.compile(optimizer='adam', loss='focal_loss', metrics=['accuracy'])

# Print model summaries
print("LeNet-5 Summary:")
print(lenet_model.summary())

print("\nDarknet-53 Summary:")
print(darknet_model.summary())
def calculate_metrics(TP, TN, FP, FN):
    epsilon = 1e-10  # Small value to avoid division by zero
    sensitivity = TP / max(TP + FN, epsilon)
    specificity = TN / max(TN + FP, epsilon)
    precision = TP / max(TP + FP, epsilon)
    recall = TP / max(TP + FN, epsilon)
    f_measure = 2 * ((precision * recall) / max(precision + recall, epsilon))
    accuracy = (TP + TN) / max(TP + TN + FP + FN, epsilon)
    mcc_numerator = (TP * TN) - (FP * FN)
    mcc_denominator = np.sqrt((TP + FP) * (TP + FN) * (TN + FP) * (TN + FN))
    mcc = mcc_numerator / max(mcc_denominator, epsilon)
    fpr = FP / max(FP + TN, epsilon)
    fnr = FN / max(FN + TP, epsilon)
    npv = TN / max(TN + FN, epsilon)
    fdr = FP / max(FP + TP, epsilon)
    return {
        'sensitivity': sensitivity, 'specificity': specificity, 'precision': precision,
        'recall': recall, 'f_measure': f_measure, 'accuracy': accuracy, 'mcc': mcc,
        'fpr': fpr, 'fnr': fnr, 'npv': npv, 'fdr': fdr
    }

def multi_label_confusion_matrix(Y_test, Y_pred):
    cm = multilabel_confusion_matrix(Y_test, Y_pred)
    num_classes = len(cm)
    TN, FP, FN, TP = cm[:, 0, 0].sum(), cm[:, 0, 1].sum(), cm[:, 1, 0].sum(), cm[:, 1, 1].sum()
    return calculate_metrics(TP, TN, FP, FN)

def binary_confusion_matrix(Y_test, Y_pred):
    cm = confusion_matrix(Y_test, Y_pred)
    TN, FP, FN, TP = cm[0, 0], cm[0, 1], cm[1, 0], cm[1, 1]
    return calculate_metrics(TP, TN, FP, FN)
# calculates precision for 1:100 dataset with 90 tp and 30 fp
# Precision calculation for binary classification
def calculate_precision(tp, fp):
    return tp / (tp + fp)

# Confusion matrix function
def plot_confusion_matrix(y_true, y_pred):
    cm = confusion_matrix(y_true, y_pred)
    plt.imshow(cm, interpolation='nearest', cmap=plt.cm.Blues)
    plt.title('Confusion Matrix')
    plt.colorbar()
    plt.xlabel('Predicted')
    plt.ylabel('Actual')
    plt.show()

# Define a function to calculate various metrics
def calculate_metrics(TP, TN, FP, FN):
    epsilon = 1e-10  # Small value to avoid division by zero
    sensitivity = TP / np.maximum(TP + FN, epsilon)
    specificity = TN / np.maximum(TN + FP, epsilon)
    precision = TP / np.maximum(TP + FP, epsilon)
    recall = TP / np.maximum(TP + FN, epsilon)
    f_measure = 2 * ((precision * recall) / np.maximum(precision + recall, epsilon))
    accuracy = (TP + TN) / np.maximum(TP + TN + FP + FN, epsilon)
    mcc_numerator = (TP * TN) - (FP * FN)
    mcc_denominator = np.sqrt((TP + FP) * (TP + FN) * (TN + FP) * (TN + FN))
    mcc = mcc_numerator / np.maximum(mcc_denominator, epsilon)
    fpr = FP / np.maximum(FP + TN, epsilon)
    fnr = FN / np.maximum(FN + TP, epsilon)
    npv = TN / np.maximum(TN + FN, epsilon)

    return {
        'sensitivity': sensitivity, 'specificity': specificity, 'precision': precision,
        'recall': recall, 'f_measure': f_measure, 'accuracy': accuracy, 'mcc': mcc,
        'fpr': fpr, 'fnr': fnr, 'npv': npv
    }


# Compile the model
model.compile(optimizer=Adam(learning_rate=0.001),
              loss='sparse_categorical_crossentropy',
              metrics=['accuracy'])

# Split the dataset into training and validation sets
x_train, x_val, y_train, y_val = train_test_split(x_train, y_train,
                                                  test_size=0.5, random_state=30)

# Train the model
history = model.fit(x_train, y_train, epochs=5, validation_data=(x_val, y_val))

# Plot training and validation accuracy
plt.figure(figsize=(12, 5))
plt.subplot(1, 2, 1)
plt.plot(history.history['accuracy'], label='Training Accuracy', marker='o')
plt.plot(history.history['val_accuracy'], label='Validation Accuracy', marker='o')
plt.title('Training and Validation Accuracy')
plt.xlabel('Epoch')
plt.ylabel('Accuracy')
plt.legend()

# Plot training and validation loss
plt.subplot(1, 2, 2)
plt.plot(history.history['loss'], label='Training Loss', marker='o')
plt.plot(history.history['val_loss'], label='Validation Loss', marker='o')
plt.title('Training and Validation Loss')
plt.xlabel('Epoch')
plt.ylabel('Loss')
plt.legend()
plt.tight_layout()
plt.show()

# Make predictions
y_pred = np.argmax(model.predict(x_test), axis=-1)

# Calculate confusion matrix
cm = confusion_matrix(y_test, y_pred)

# Extract TP, TN, FP, FN from confusion matrix
TP = np.diag(cm)
FP = np.sum(cm, axis=0) - TP
FN = np.sum(cm, axis=1) - TP
TN = np.sum(cm) - (TP + FP + FN)

# Calculate metrics
metrics = calculate_metrics(TP, TN, FP, FN)

# Print metrics
for metric_name, metric_value in metrics.items():
    print(f'{metric_name}: {metric_value}')

"""# **CNN Algorithm**"""

import tensorflow as tf
from tensorflow.keras import layers, models, datasets
import numpy as np
from sklearn.metrics import confusion_matrix, precision_score, recall_score, f1_score
import tensorflow as tf
from tensorflow.keras.datasets import mnist
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Flatten, Dense
from tensorflow.keras.optimizers import Adam
from sklearn.model_selection import train_test_split
import matplotlib.pyplot as plt


# Define the model architecture
model = models.Sequential([
    layers.Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)),
    layers.MaxPooling2D((2, 2)),
    layers.Conv2D(64, (3, 3), activation='relu'),
    layers.MaxPooling2D((2, 2)),
    layers.Conv2D(64, (3, 3), activation='relu'),
    layers.Flatten(),
    layers.Dense(64, activation='relu'),
    layers.Dense(10, activation='softmax')
])

# Compile the model
model.compile(optimizer='adam',
              loss='sparse_categorical_crossentropy',
              metrics=['accuracy'])

# Train the model
history = model.fit(train_images, train_labels, epochs=5, validation_data=(test_images, test_labels))

# Evaluate the model
test_loss, test_acc = model.evaluate(test_images, test_labels, verbose=2)
# Precision calculation for binary classification
def calculate_precision(tp, fp):
    return tp / (tp + fp)

# Confusion matrix function
def plot_confusion_matrix(y_true, y_pred):
    cm = confusion_matrix(y_true, y_pred)
    plt.imshow(cm, interpolation='nearest', cmap=plt.cm.Blues)
    plt.title('Confusion Matrix')
    plt.colorbar()
    plt.xlabel('Predicted')
    plt.ylabel('Actual')
    plt.show()

# Define a function to calculate various metrics
def calculate_metrics(TP, TN, FP, FN):
    epsilon = 1e-10  # Small value to avoid division by zero
    sensitivity = TP / np.maximum(TP + FN, epsilon)
    specificity = TN / np.maximum(TN + FP, epsilon)
    precision = TP / np.maximum(TP + FP, epsilon)
    recall = TP / np.maximum(TP + FN, epsilon)
    f_measure = 2 * ((precision * recall) / np.maximum(precision + recall, epsilon))
    accuracy = (TP + TN) / np.maximum(TP + TN + FP + FN, epsilon)
    mcc_numerator = (TP * TN) - (FP * FN)
    mcc_denominator = np.sqrt((TP + FP) * (TP + FN) * (TN + FP) * (TN + FN))
    mcc = mcc_numerator / np.maximum(mcc_denominator, epsilon)
    fpr = FP / np.maximum(FP + TN, epsilon)
    fnr = FN / np.maximum(FN + TP, epsilon)
    npv = TN / np.maximum(TN + FN, epsilon)

    return {
        'sensitivity': sensitivity, 'specificity': specificity, 'precision': precision,
        'recall': recall, 'f_measure': f_measure, 'accuracy': accuracy, 'mcc': mcc,
        'fpr': fpr, 'fnr': fnr, 'npv': npv
    }



# Split the dataset into training and validation sets
x_train, x_val, y_train, y_val = train_test_split(x_train, y_train,
                                                  test_size=0.5, random_state=30)

# Train the model
history = model.fit(x_train, y_train, epochs=5, validation_data=(x_val, y_val))

# Plot training and validation accuracy
plt.figure(figsize=(12, 5))
plt.subplot(1, 2, 1)
plt.plot(history.history['accuracy'], label='Training Accuracy', marker='o')
plt.plot(history.history['val_accuracy'], label='Validation Accuracy', marker='o')
plt.title('Training and Validation Accuracy')
plt.xlabel('Epoch')
plt.ylabel('Accuracy')
plt.legend()

# Plot training and validation loss
plt.subplot(1, 2, 2)
plt.plot(history.history['loss'], label='Training Loss', marker='o')
plt.plot(history.history['val_loss'], label='Validation Loss', marker='o')
plt.title('Training and Validation Loss')
plt.xlabel('Epoch')
plt.ylabel('Loss')
plt.legend()
plt.tight_layout()
plt.show()

# Make predictions
y_pred = np.argmax(model.predict(x_test), axis=-1)

# Calculate confusion matrix
cm = confusion_matrix(y_test, y_pred)

# Extract TP, TN, FP, FN from confusion matrix
TP = np.diag(cm)
FP = np.sum(cm, axis=0) - TP
FN = np.sum(cm, axis=1) - TP
TN = np.sum(cm) - (TP + FP + FN)

# Calculate metrics
metrics = calculate_metrics(TP, TN, FP, FN)

# Print metrics
for metric_name, metric_value in metrics.items():
    print(f'{metric_name}: {metric_value}')

"""# **VGG-19**"""

import numpy as np
import tensorflow as tf
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense
import numpy as np
from sklearn.metrics import confusion_matrix, precision_score, recall_score, f1_score
import tensorflow as tf
from tensorflow.keras.datasets import mnist
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Flatten, Dense
from tensorflow.keras.optimizers import Adam
from sklearn.model_selection import train_test_split
import matplotlib.pyplot as plt

def VGG_19(input_shape=(224, 224, 3), num_classes=1000):
    model = Sequential()

    # Block 1
    model.add(Conv2D(64, (3, 3), activation='relu', padding='same', input_shape=input_shape))
    model.add(Conv2D(64, (3, 3), activation='relu', padding='same'))
    model.add(MaxPooling2D((2, 2), strides=(2, 2)))

    # Block 2
    model.add(Conv2D(128, (3, 3), activation='relu', padding='same'))
    model.add(Conv2D(128, (3, 3), activation='relu', padding='same'))
    model.add(MaxPooling2D((2, 2), strides=(2, 2)))

    # Block 3
    model.add(Conv2D(256, (3, 3), activation='relu', padding='same'))
    model.add(Conv2D(256, (3, 3), activation='relu', padding='same'))
    model.add(Conv2D(256, (3, 3), activation='relu', padding='same'))
    model.add(Conv2D(256, (3, 3), activation='relu', padding='same'))
    model.add(MaxPooling2D((2, 2), strides=(2, 2)))

    # Block 4
    model.add(Conv2D(512, (3, 3), activation='relu', padding='same'))
    model.add(Conv2D(512, (3, 3), activation='relu', padding='same'))
    model.add(Conv2D(512, (3, 3), activation='relu', padding='same'))
    model.add(Conv2D(512, (3, 3), activation='relu', padding='same'))
    model.add(MaxPooling2D((2, 2), strides=(2, 2)))

    # Block 5
    model.add(Conv2D(512, (3, 3), activation='relu', padding='same'))
    model.add(Conv2D(512, (3, 3), activation='relu', padding='same'))
    model.add(Conv2D(512, (3, 3), activation='relu', padding='same'))
    model.add(Conv2D(512, (3, 3), activation='relu', padding='same'))
    model.add(MaxPooling2D((2, 2), strides=(2, 2)))

    # Classification block
    model.add(Flatten())
    model.add(Dense(4096, activation='relu'))
    model.add(Dense(4096, activation='relu'))
    model.add(Dense(num_classes, activation='softmax'))

    return model

# Example usage:
input_shape = (224, 224, 3)  # Input shape of your images
num_classes = 1000  # Number of classes in your dataset

vgg19_model = VGG_19(input_shape=input_shape, num_classes=num_classes)
vgg19_model.summary()
def calculate_precision(tp, fp):
    return tp / (tp + fp)

# Confusion matrix function
def plot_confusion_matrix(y_true, y_pred):
    cm = confusion_matrix(y_true, y_pred)
    plt.imshow(cm, interpolation='nearest', cmap=plt.cm.Blues)
    plt.title('Confusion Matrix')
    plt.colorbar()
    plt.xlabel('Predicted')
    plt.ylabel('Actual')
    plt.show()

# Define a function to calculate various metrics
def calculate_metrics(TP, TN, FP, FN):
    epsilon = 1e-10  # Small value to avoid division by zero
    sensitivity = TP / np.maximum(TP + FN, epsilon)
    specificity = TN / np.maximum(TN + FP, epsilon)
    precision = TP / np.maximum(TP + FP, epsilon)
    recall = TP / np.maximum(TP + FN, epsilon)
    f_measure = 2 * ((precision * recall) / np.maximum(precision + recall, epsilon))
    accuracy = (TP + TN) / np.maximum(TP + TN + FP + FN, epsilon)
    mcc_numerator = (TP * TN) - (FP * FN)
    mcc_denominator = np.sqrt((TP + FP) * (TP + FN) * (TN + FP) * (TN + FN))
    mcc = mcc_numerator / np.maximum(mcc_denominator, epsilon)
    fpr = FP / np.maximum(FP + TN, epsilon)
    fnr = FN / np.maximum(FN + TP, epsilon)
    npv = TN / np.maximum(TN + FN, epsilon)

    return {
        'sensitivity': sensitivity, 'specificity': specificity, 'precision': precision,
        'recall': recall, 'f_measure': f_measure, 'accuracy': accuracy, 'mcc': mcc,
        'fpr': fpr, 'fnr': fnr, 'npv': npv
    }

# Compile the model
model.compile(optimizer=Adam(learning_rate=0.0154),
              loss='sparse_categorical_crossentropy',
              metrics=['accuracy'])

# Split the dataset into training and validation sets
x_train, x_val, y_train, y_val = train_test_split(x_train, y_train,
                                                  test_size=0.5, random_state=30)

# Train the model
history = model.fit(x_train, y_train, epochs=5, validation_data=(x_val, y_val))

# Plot training and validation accuracy
plt.figure(figsize=(12, 5))
plt.subplot(1, 2, 1)
plt.plot(history.history['accuracy'], label='Training Accuracy', marker='o')
plt.plot(history.history['val_accuracy'], label='Validation Accuracy', marker='o')
plt.title('Training and Validation Accuracy')
plt.xlabel('Epoch')
plt.ylabel('Accuracy')
plt.legend()

# Plot training and validation loss
plt.subplot(1, 2, 2)
plt.plot(history.history['loss'], label='Training Loss', marker='o')
plt.plot(history.history['val_loss'], label='Validation Loss', marker='o')
plt.title('Training and Validation Loss')
plt.xlabel('Epoch')
plt.ylabel('Loss')
plt.legend()
plt.tight_layout()
plt.show()

# Make predictions
y_pred = np.argmax(model.predict(x_test), axis=-1)

# Calculate confusion matrix
cm = confusion_matrix(y_test, y_pred)

# Extract TP, TN, FP, FN from confusion matrix
TP = np.diag(cm)
FP = np.sum(cm, axis=0) - TP
FN = np.sum(cm, axis=1) - TP
TN = np.sum(cm) - (TP + FP + FN)

# Calculate metrics
metrics = calculate_metrics(TP, TN, FP, FN)

# Print metrics
for metric_name, metric_value in metrics.items():
    print(f'{metric_name}: {metric_value}')

"""# **DCNN**"""

import tensorflow as tf
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout
import numpy as np
from sklearn.metrics import confusion_matrix, precision_score, recall_score, f1_score
import tensorflow as tf
from tensorflow.keras.datasets import mnist
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Flatten, Dense
from tensorflow.keras.optimizers import Adam
from sklearn.model_selection import train_test_split
import matplotlib.pyplot as plt


def build_dcnn(input_shape, num_classes):
    model = Sequential([
        Conv2D(32, (3, 3), activation='relu', input_shape=input_shape),
        MaxPooling2D((2, 2)),
        Conv2D(64, (3, 3), activation='relu'),
        MaxPooling2D((2, 2)),
        Conv2D(128, (3, 3), activation='relu'),
        MaxPooling2D((2, 2)),
        Conv2D(128, (3, 3), activation='relu'),
        MaxPooling2D((2, 2)),
        Flatten(),
        Dropout(0.5),
        Dense(512, activation='relu'),
        Dense(num_classes, activation='softmax')
    ])
    return model

# Example usage:
input_shape = (150, 150, 3)  # Input shape of your images
num_classes = 10  # Number of classes in your dataset

dcnn_model = build_dcnn(input_shape, num_classes)
dcnn_model.summary()
def calculate_precision(tp, fp):
    return tp / (tp + fp)

# Confusion matrix function
def plot_confusion_matrix(y_true, y_pred):
    cm = confusion_matrix(y_true, y_pred)
    plt.imshow(cm, interpolation='nearest', cmap=plt.cm.Blues)
    plt.title('Confusion Matrix')
    plt.colorbar()
    plt.xlabel('Predicted')
    plt.ylabel('Actual')
    plt.show()

# Define a function to calculate various metrics
def calculate_metrics(TP, TN, FP, FN):
    epsilon = 1e-10  # Small value to avoid division by zero
    sensitivity = TP / np.maximum(TP + FN, epsilon)
    specificity = TN / np.maximum(TN + FP, epsilon)
    precision = TP / np.maximum(TP + FP, epsilon)
    recall = TP / np.maximum(TP + FN, epsilon)
    f_measure = 2 * ((precision * recall) / np.maximum(precision + recall, epsilon))
    accuracy = (TP + TN) / np.maximum(TP + TN + FP + FN, epsilon)
    mcc_numerator = (TP * TN) - (FP * FN)
    mcc_denominator = np.sqrt((TP + FP) * (TP + FN) * (TN + FP) * (TN + FN))
    mcc = mcc_numerator / np.maximum(mcc_denominator, epsilon)
    fpr = FP / np.maximum(FP + TN, epsilon)
    fnr = FN / np.maximum(FN + TP, epsilon)
    npv = TN / np.maximum(TN + FN, epsilon)

    return {
        'sensitivity': sensitivity, 'specificity': specificity, 'precision': precision,
        'recall': recall, 'f_measure': f_measure, 'accuracy': accuracy, 'mcc': mcc,
        'fpr': fpr, 'fnr': fnr, 'npv': npv
    }




# Compile the model
model.compile(optimizer=Adam(learning_rate=0.019),
              loss='sparse_categorical_crossentropy',
              metrics=['accuracy'])

# Split the dataset into training and validation sets
x_train, x_val, y_train, y_val = train_test_split(x_train, y_train,
                                                  test_size=0.5, random_state=30)

# Train the model
history = model.fit(x_train, y_train, epochs=5, validation_data=(x_val, y_val))

# Plot training and validation accuracy
plt.figure(figsize=(12, 5))
plt.subplot(1, 2, 1)
plt.plot(history.history['accuracy'], label='Training Accuracy', marker='o')
plt.plot(history.history['val_accuracy'], label='Validation Accuracy', marker='o')
plt.title('Training and Validation Accuracy')
plt.xlabel('Epoch')
plt.ylabel('Accuracy')
plt.legend()

# Plot training and validation loss
plt.subplot(1, 2, 2)
plt.plot(history.history['loss'], label='Training Loss', marker='o')
plt.plot(history.history['val_loss'], label='Validation Loss', marker='o')
plt.title('Training and Validation Loss')
plt.xlabel('Epoch')
plt.ylabel('Loss')
plt.legend()
plt.tight_layout()
plt.show()

# Make predictions
y_pred = np.argmax(model.predict(x_test), axis=-1)

# Calculate confusion matrix
cm = confusion_matrix(y_test, y_pred)

# Extract TP, TN, FP, FN from confusion matrix
TP = np.diag(cm)
FP = np.sum(cm, axis=0) - TP
FN = np.sum(cm, axis=1) - TP
TN = np.sum(cm) - (TP + FP + FN)

# Calculate metrics
metrics = calculate_metrics(TP, TN, FP, FN)

# Print metrics
for metric_name, metric_value in metrics.items():
    print(f'{metric_name}: {metric_value}')

"""# **MLP**"""

import tensorflow as tf
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, Dropout
import numpy as np
from sklearn.metrics import confusion_matrix, precision_score, recall_score, f1_score
import tensorflow as tf
from tensorflow.keras.datasets import mnist
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Flatten, Dense
from tensorflow.keras.optimizers import Adam
from sklearn.model_selection import train_test_split
import matplotlib.pyplot as plt
def build_mlp(input_shape, num_classes):
    model = Sequential([
        Dense(128, activation='relu', input_shape=input_shape),
        Dropout(0.5),
        Dense(64, activation='relu'),
        Dropout(0.5),
        Dense(num_classes, activation='softmax')
    ])
    return model

# Example usage:
input_shape = (784,)  # Input shape of your data
num_classes = 10  # Number of classes in your dataset

mlp_model = build_mlp(input_shape, num_classes)
mlp_model.summary()
def calculate_precision(tp, fp):
    return tp / (tp + fp)

# Confusion matrix function
def plot_confusion_matrix(y_true, y_pred):
    cm = confusion_matrix(y_true, y_pred)
    plt.imshow(cm, interpolation='nearest', cmap=plt.cm.Blues)
    plt.title('Confusion Matrix')
    plt.colorbar()
    plt.xlabel('Predicted')
    plt.ylabel('Actual')
    plt.show()

# Define a function to calculate various metrics
def calculate_metrics(TP, TN, FP, FN):
    epsilon = 1e-10  # Small value to avoid division by zero
    sensitivity = TP / np.maximum(TP + FN, epsilon)
    specificity = TN / np.maximum(TN + FP, epsilon)
    precision = TP / np.maximum(TP + FP, epsilon)
    recall = TP / np.maximum(TP + FN, epsilon)
    f_measure = 2 * ((precision * recall) / np.maximum(precision + recall, epsilon))
    accuracy = (TP + TN) / np.maximum(TP + TN + FP + FN, epsilon)
    mcc_numerator = (TP * TN) - (FP * FN)
    mcc_denominator = np.sqrt((TP + FP) * (TP + FN) * (TN + FP) * (TN + FN))
    mcc = mcc_numerator / np.maximum(mcc_denominator, epsilon)
    fpr = FP / np.maximum(FP + TN, epsilon)
    fnr = FN / np.maximum(FN + TP, epsilon)
    npv = TN / np.maximum(TN + FN, epsilon)

    return {
        'sensitivity': sensitivity, 'specificity': specificity, 'precision': precision,
        'recall': recall, 'f_measure': f_measure, 'accuracy': accuracy, 'mcc': mcc,
        'fpr': fpr, 'fnr': fnr, 'npv': npv
    }


# Compile the model
model.compile(optimizer=Adam(learning_rate=0.009),
              loss='sparse_categorical_crossentropy',
              metrics=['accuracy'])

# Split the dataset into training and validation sets
x_train, x_val, y_train, y_val = train_test_split(x_train, y_train,
                                                  test_size=0.5, random_state=30)

# Train the model
history = model.fit(x_train, y_train, epochs=5, validation_data=(x_val, y_val))

# Plot training and validation accuracy
plt.figure(figsize=(12, 5))
plt.subplot(1, 2, 1)
plt.plot(history.history['accuracy'], label='Training Accuracy', marker='o')
plt.plot(history.history['val_accuracy'], label='Validation Accuracy', marker='o')
plt.title('Training and Validation Accuracy')
plt.xlabel('Epoch')
plt.ylabel('Accuracy')
plt.legend()

# Plot training and validation loss
plt.subplot(1, 2, 2)
plt.plot(history.history['loss'], label='Training Loss', marker='o')
plt.plot(history.history['val_loss'], label='Validation Loss', marker='o')
plt.title('Training and Validation Loss')
plt.xlabel('Epoch')
plt.ylabel('Loss')
plt.legend()
plt.tight_layout()
plt.show()

# Make predictions
y_pred = np.argmax(model.predict(x_test), axis=-1)

# Calculate confusion matrix
cm = confusion_matrix(y_test, y_pred)

# Extract TP, TN, FP, FN from confusion matrix
TP = np.diag(cm)
FP = np.sum(cm, axis=0) - TP
FN = np.sum(cm, axis=1) - TP
TN = np.sum(cm) - (TP + FP + FN)

# Calculate metrics
metrics = calculate_metrics(TP, TN, FP, FN)

# Print metrics
for metric_name, metric_value in metrics.items():
    print(f'{metric_name}: {metric_value}')

"""# **Comparrison Table**"""

import numpy as np
import matplotlib.pyplot as plt

# Set width of bar
barWidth = 0.10
fig, ax = plt.subplots(figsize=(12, 8))

# Set sensitivity values
FusionNet_2 = [98.619, 99.113]
vgg_19 = [95.639, 95.639]
dcnn = [96.402, 96.402]
mlp = [94.481, 94.481]
cnn = [95.071, 95.071]

# Set position of bar on X axis
br1 = np.arange(len(FusionNet_2))
br2 = [x + barWidth for x in br1]
br3 = [x + barWidth for x in br2]
br4 = [x + barWidth for x in br3]
br5 = [x + barWidth for x in br4]

# Make the plot
ax.bar(br1, FusionNet_2, color='r', width=barWidth, edgecolor='grey', label='FusionNet-2')
plt.bar(br2, vgg_19, color='g', width=barWidth, edgecolor='grey', label='VGG-19 [16]')
plt.bar(br3, dcnn, color='b', width=barWidth, edgecolor='grey', label='DCNN [19]')
plt.bar(br4, mlp, color='y', width=barWidth, edgecolor='grey', label='MLP [23]')
plt.bar(br5, cnn, color='c', width=barWidth, edgecolor='grey', label='CNN [24]')

# Adding Xticks
ax.set_xlabel('Model', fontweight='bold', fontsize=15)
ax.set_ylabel('Sensitivity', fontweight='bold', fontsize=15)
ax.set_xticks([r + 2*barWidth for r in range(len(FusionNet_2))])
ax.set_xticklabels(['Learning Rate 70/30', 'Learning Rate 80/20'])

plt.legend()
plt.show()
import numpy as np
import matplotlib.pyplot as plt

# Set width of bar
barWidth = 0.10
fig, ax = plt.subplots(figsize=(12, 8))

# Set specificity values
FusionNet_2 = [98.792, 99.014]
vgg_19 = [95.52, 95.52]
dcnn = [96.481, 96.481]
mlp = [94.329, 94.329]
cnn = [95.82, 95.82]

# Set position of bar on X axis
br1 = np.arange(len(FusionNet_2))
br2 = [x + barWidth for x in br1]
br3 = [x + barWidth for x in br2]
br4 = [x + barWidth for x in br3]
br5 = [x + barWidth for x in br4]

# Make the plot
ax.bar(br1, FusionNet_2, color='r', width=barWidth, edgecolor='grey', label='FusionNet-2')
plt.bar(br2, vgg_19, color='g', width=barWidth, edgecolor='grey', label='VGG-19 [16]')
plt.bar(br3, dcnn, color='b', width=barWidth, edgecolor='grey', label='DCNN [19]')
plt.bar(br4, mlp, color='y', width=barWidth, edgecolor='grey', label='MLP [23]')
plt.bar(br5, cnn, color='c', width=barWidth, edgecolor='grey', label='CNN [24]')

# Adding Xticks
ax.set_xlabel('Model', fontweight='bold', fontsize=15)
ax.set_ylabel('Specificity', fontweight='bold', fontsize=15)
ax.set_xticks([r + 2*barWidth for r in range(len(FusionNet_2))])
ax.set_xticklabels(['Learning Rate 70/30', 'Learning Rate 80/20'])

plt.legend()
plt.show()
import numpy as np
import matplotlib.pyplot as plt

# Set width of bar
barWidth = 0.10
fig, ax = plt.subplots(figsize=(12, 8))

# Set F-measure values
FusionNet_2 = [98.621, 99.083]
vgg_19 = [95.402, 95.402]
dcnn = [96.194, 96.194]
mlp = [94.629, 94.629]
cnn = [95.726, 95.726]

# Set position of bar on X axis
br1 = np.arange(len(FusionNet_2))
br2 = [x + barWidth for x in br1]
br3 = [x + barWidth for x in br2]
br4 = [x + barWidth for x in br3]
br5 = [x + barWidth for x in br4]

# Make the plot
ax.bar(br1, FusionNet_2, color='r', width=barWidth, edgecolor='grey', label='FusionNet-2')
plt.bar(br2, vgg_19, color='g', width=barWidth, edgecolor='grey', label='VGG-19 [16]')
plt.bar(br3, dcnn, color='b', width=barWidth, edgecolor='grey', label='DCNN [19]')
plt.bar(br4, mlp, color='y', width=barWidth, edgecolor='grey', label='MLP [23]')
plt.bar(br5, cnn, color='c', width=barWidth, edgecolor='grey', label='CNN [24]')

# Adding Xticks
ax.set_xlabel('Model', fontweight='bold', fontsize=15)
ax.set_ylabel('F-measure', fontweight='bold', fontsize=15)
ax.set_xticks([r + 2*barWidth for r in range(len(FusionNet_2))])
ax.set_xticklabels(['Learning Rate 70/30', 'Learning Rate 80/20'])

plt.legend()
plt.show()
import numpy as np
import matplotlib.pyplot as plt

# Set width of bar
barWidth = 0.10
fig, ax = plt.subplots(figsize=(12, 8))

# Set NPV values
FusionNet_2 = [98.205, 99.037]
vgg_19 = [95.928, 95.928]
dcnn = [96.251, 96.251]
mlp = [94.438, 94.438]
cnn = [95.617, 95.617]

# Set position of bar on X axis
br1 = np.arange(len(FusionNet_2))
br2 = [x + barWidth for x in br1]
br3 = [x + barWidth for x in br2]
br4 = [x + barWidth for x in br3]
br5 = [x + barWidth for x in br4]

# Make the plot
ax.bar(br1, FusionNet_2, color='r', width=barWidth, edgecolor='grey', label='FusionNet-2')
plt.bar(br2, vgg_19, color='g', width=barWidth, edgecolor='grey', label='VGG-19 [16]')
plt.bar(br3, dcnn, color='b', width=barWidth, edgecolor='grey', label='DCNN [19]')
plt.bar(br4, mlp, color='y', width=barWidth, edgecolor='grey', label='MLP [23]')
plt.bar(br5, cnn, color='c', width=barWidth, edgecolor='grey', label='CNN [24]')

# Adding Xticks
ax.set_xlabel('Model', fontweight='bold', fontsize=15)
ax.set_ylabel('NPV', fontweight='bold', fontsize=15)
ax.set_xticks([r + 2*barWidth for r in range(len(FusionNet_2))])
ax.set_xticklabels(['Learning Rate 70/30', 'Learning Rate 80/20'])

plt.legend()
plt.show()
import numpy as np
import matplotlib.pyplot as plt

# Set width of bar
barWidth = 0.10
fig, ax = plt.subplots(figsize=(12, 8))

# Set FPR (False Positive Rate) values
FusionNet_2 = [0.0214, 0.0114]
vgg_19 = [0.0431, 0.0331]
dcnn = [0.0464, 0.0224]
mlp = [0.0572, 0.0414]
cnn = [0.0501, 0.0428]

# Set position of bar on X axis
br1 = np.arange(len(FusionNet_2))
br2 = [x + barWidth for x in br1]
br3 = [x + barWidth for x in br2]
br4 = [x + barWidth for x in br3]
br5 = [x + barWidth for x in br4]

# Make the plot
ax.bar(br1, FusionNet_2, color='r', width=barWidth, edgecolor='grey', label='FusionNet-2')
plt.bar(br2, vgg_19, color='g', width=barWidth, edgecolor='grey', label='VGG-19 [16]')
plt.bar(br3, dcnn, color='b', width=barWidth, edgecolor='grey', label='DCNN [19]')
plt.bar(br4, mlp, color='y', width=barWidth, edgecolor='grey', label='MLP [23]')
plt.bar(br5, cnn, color='c', width=barWidth, edgecolor='grey', label='CNN [24]')

# Adding Xticks
ax.set_xlabel('Model', fontweight='bold', fontsize=15)
ax.set_ylabel('FPR', fontweight='bold', fontsize=15)
ax.set_xticks([r + 2*barWidth for r in range(len(FusionNet_2))])
ax.set_xticklabels(['Learning Rate 70/30', 'Learning Rate 80/20'])

plt.legend()
plt.show()
import numpy as np
import matplotlib.pyplot as plt

# Set width of bar
barWidth = 0.10
fig, ax = plt.subplots(figsize=(12, 8))

# Set FNR (False Negative Rate) values
FusionNet_2 = [0.0202, 0.0102]
vgg_19 = [0.0356, 0.0256]
dcnn = [0.0416, 0.0326]
mlp = [0.0468, 0.0351]
cnn = [0.0491, 0.0327]

# Set position of bar on X axis
br1 = np.arange(len(FusionNet_2))
br2 = [x + barWidth for x in br1]
br3 = [x + barWidth for x in br2]
br4 = [x + barWidth for x in br3]
br5 = [x + barWidth for x in br4]

# Make the plot
ax.bar(br1, FusionNet_2, color='r', width=barWidth, edgecolor='grey', label='FusionNet-2')
plt.bar(br2, vgg_19, color='g', width=barWidth, edgecolor='grey', label='VGG-19 [16]')
plt.bar(br3, dcnn, color='b', width=barWidth, edgecolor='grey', label='DCNN [19]')
plt.bar(br4, mlp, color='y', width=barWidth, edgecolor='grey', label='MLP [23]')
plt.bar(br5, cnn, color='c', width=barWidth, edgecolor='grey', label='CNN [24]')

# Adding Xticks
ax.set_xlabel('Model', fontweight='bold', fontsize=15)
ax.set_ylabel('FNR', fontweight='bold', fontsize=15)
ax.set_xticks([r + 2*barWidth for r in range(len(FusionNet_2))])
ax.set_xticklabels(['Learning Rate 70/30', 'Learning Rate 80/20'])

plt.legend()
plt.show()
import numpy as np
import matplotlib.pyplot as plt

# Set width of bar
barWidth = 0.10
fig, ax = plt.subplots(figsize=(12, 8))

# Set MCC (Matthews Correlation Coefficient) values
FusionNet_2 = [98.563, 99.362]
vgg_19 = [95.732, 95.406]
dcnn = [96.301, 96.393]
mlp = [94.648, 94.579]
cnn = [95.418, 95.274]

# Set position of bar on X axis
br1 = np.arange(len(FusionNet_2))
br2 = [x + barWidth for x in br1]
br3 = [x + barWidth for x in br2]
br4 = [x + barWidth for x in br3]
br5 = [x + barWidth for x in br4]

# Make the plot
ax.bar(br1, FusionNet_2, color='r', width=barWidth, edgecolor='grey', label='FusionNet-2')
plt.bar(br2, vgg_19, color='g', width=barWidth, edgecolor='grey', label='VGG-19 [16]')
plt.bar(br3, dcnn, color='b', width=barWidth, edgecolor='grey', label='DCNN [19]')
plt.bar(br4, mlp, color='y', width=barWidth, edgecolor='grey', label='MLP [23]')
plt.bar(br5, cnn, color='c', width=barWidth, edgecolor='grey', label='CNN [24]')

# Adding Xticks
ax.set_xlabel('Model', fontweight='bold', fontsize=15)
ax.set_ylabel('MCC', fontweight='bold', fontsize=15)
ax.set_xticks([r + 2*barWidth for r in range(len(FusionNet_2))])
ax.set_xticklabels(['Learning Rate 70/30', 'Learning Rate 80/20'])

plt.legend()
plt.show()
import numpy as np
import matplotlib.pyplot as plt

# Set width of bar
barWidth = 0.10
fig, ax = plt.subplots(figsize=(12, 8))

# Set accuracy values
FusionNet_2 = [98.345, 99.168]
vgg_19 = [95.643, 95.643]
dcnn = [96.459, 96.459]
mlp = [94.376, 94.376]
cnn = [95.629, 95.629]

# Set position of bar on X axis
br1 = np.arange(len(FusionNet_2))
br2 = [x + barWidth for x in br1]
br3 = [x + barWidth for x in br2]
br4 = [x + barWidth for x in br3]
br5 = [x + barWidth for x in br4]

# Make the plot
ax.bar(br1, FusionNet_2, color='r', width=barWidth, edgecolor='grey', label='FusionNet-2')
plt.bar(br2, vgg_19, color='g', width=barWidth, edgecolor='grey', label='VGG-19 [16]')
plt.bar(br3, dcnn, color='b', width=barWidth, edgecolor='grey', label='DCNN [19]')
plt.bar(br4, mlp, color='y', width=barWidth, edgecolor='grey', label='MLP [23]')
plt.bar(br5, cnn, color='c', width=barWidth, edgecolor='grey', label='CNN [24]')

# Adding Xticks
ax.set_xlabel('Model', fontweight='bold', fontsize=15)
ax.set_ylabel('Accuracy', fontweight='bold', fontsize=15)
ax.set_xticks([r + 2*barWidth for r in range(len(FusionNet_2))])
ax.set_xticklabels(['Learning Rate 70/30', 'Learning Rate 80/20'])

plt.legend()
plt.show()
import numpy as np
import matplotlib.pyplot as plt

# Set width of bar
barWidth = 0.10
fig, ax = plt.subplots(figsize=(12, 8))

# Set precision values
FusionNet_2 = [98.482, 99.322]
vgg_19 = [95.729, 95.729]
dcnn = [96.739, 96.739]
mlp = [94.723, 94.723]
cnn = [95.749, 95.749]

# Set position of bar on X axis
br1 = np.arange(len(FusionNet_2))
br2 = [x + barWidth for x in br1]
br3 = [x + barWidth for x in br2]
br4 = [x + barWidth for x in br3]
br5 = [x + barWidth for x in br4]

# Make the plot
ax.bar(br1, FusionNet_2, color='r', width=barWidth, edgecolor='grey', label='FusionNet-2')
plt.bar(br2, vgg_19, color='g', width=barWidth, edgecolor='grey', label='VGG-19 [16]')
plt.bar(br3, dcnn, color='b', width=barWidth, edgecolor='grey', label='DCNN [19]')
plt.bar(br4, mlp, color='y', width=barWidth, edgecolor='grey', label='MLP [23]')
plt.bar(br5, cnn, color='c', width=barWidth, edgecolor='grey', label='CNN [24]')

# Adding Xticks
ax.set_xlabel('Model', fontweight='bold', fontsize=15)
ax.set_ylabel('Precision', fontweight='bold', fontsize=15)
ax.set_xticks([r + 2*barWidth for r in range(len(FusionNet_2))])
ax.set_xticklabels(['Learning Rate 70/30', 'Learning Rate 80/20'])

plt.legend()
plt.show()